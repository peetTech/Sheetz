{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4386c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc396605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.mkdir('./working/data')\n",
    "os.mkdir('./working/data/images')\n",
    "os.mkdir('./working/data/labels')\n",
    "\n",
    "os.mkdir('./working/data/images/train')\n",
    "os.mkdir('./working/data/images/valid')\n",
    "\n",
    "os.mkdir('./working/data/labels/train')\n",
    "os.mkdir('./working/data/labels/valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "793a0796",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./working/new_train_yaml', 'w+') as file:\n",
    "    file.write(\n",
    "        \"\"\"\n",
    "        # parameters\n",
    "        nc: 1  # number of classes\n",
    "        depth_multiple: 0.33  # model depth multiple\n",
    "        width_multiple: 0.50  # layer channel multiple\n",
    "\n",
    "        # anchors\n",
    "        anchors:\n",
    "          - [10,13, 16,30, 33,23]  # P3/8\n",
    "          - [30,61, 62,45, 59,119]  # P4/16\n",
    "          - [116,90, 156,198, 373,326]  # P5/32\n",
    "\n",
    "        # YOLOv5 backbone\n",
    "        backbone:\n",
    "          # [from, number, module, args]\n",
    "          [[-1, 1, Focus, [64, 3]],  # 0-P1/2\n",
    "           [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n",
    "           [-1, 3, BottleneckCSP, [128]],\n",
    "           [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n",
    "           [-1, 9, BottleneckCSP, [256]],\n",
    "           [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n",
    "           [-1, 9, BottleneckCSP, [512]],\n",
    "           [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n",
    "           [-1, 1, SPP, [1024, [5, 9, 13]]],\n",
    "           [-1, 3, BottleneckCSP, [1024, False]],  # 9\n",
    "          ]\n",
    "\n",
    "        # YOLOv5 head\n",
    "        head:\n",
    "          [[-1, 1, Conv, [512, 1, 1]],\n",
    "           [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
    "           [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n",
    "           [-1, 3, BottleneckCSP, [512, False]],  # 13\n",
    "\n",
    "           [-1, 1, Conv, [256, 1, 1]],\n",
    "           [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
    "           [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n",
    "           [-1, 3, BottleneckCSP, [256, False]],  # 17 (P3/8-small)\n",
    "\n",
    "           [-1, 1, Conv, [256, 3, 2]],\n",
    "           [[-1, 14], 1, Concat, [1]],  # cat head P4\n",
    "           [-1, 3, BottleneckCSP, [512, False]],  # 20 (P4/16-medium)\n",
    "\n",
    "           [-1, 1, Conv, [512, 3, 2]],\n",
    "           [[-1, 10], 1, Concat, [1]],  # cat head P5\n",
    "           [-1, 3, BottleneckCSP, [1024, False]],  # 23 (P5/32-large)\n",
    "\n",
    "           [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n",
    "          ]\n",
    "        \"\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45cd8324",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./working/new_data_yaml', 'w+') as file:\n",
    "    file.write(\n",
    "        \"\"\"\n",
    "        train: ./working/data/images/train\n",
    "        val: ./working/data/images/valid\n",
    "\n",
    "        nc: 1\n",
    "        names: ['cans']\n",
    "        \"\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ac2f7cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=last_yolov5s_results.pt, cfg=./models/yolov5s.yaml, data=./working/new_data_yaml, hyp=data/hyps/hyp.scratch.yaml, epochs=10, batch_size=10, imgsz=400, rect=False, resume=False, nosave=True, noval=False, noautoanchor=False, evolve=None, bucket=, cache_images=True, image_weights=False, device=, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, project=runs/train, entity=None, name=joos, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias=latest, local_rank=-1\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m‚ö†Ô∏è WARNING: code is out of date by 26 commits. Use 'git pull' to update or 'git clone https://github.com/ultralytics/yolov5' to download latest.\n",
      "YOLOv5 üöÄ v5.0-301-g0cc7c58 torch 1.9.0+cu102 CUDA:0 (Tesla T4, 15109.75MB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "2021-07-29 10:27:07.071487: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:671: SourceChangeWarning: source code of class 'models.yolo.Model' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.container.Sequential' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:671: SourceChangeWarning: source code of class 'models.common.Focus' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:671: SourceChangeWarning: source code of class 'models.common.Conv' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.batchnorm.BatchNorm2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.activation.LeakyReLU' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:671: SourceChangeWarning: source code of class 'models.common.Bottleneck' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:671: SourceChangeWarning: source code of class 'models.common.BottleneckCSP' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:671: SourceChangeWarning: source code of class 'models.common.SPP' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.container.ModuleList' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.pooling.MaxPool2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.upsampling.Upsample' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:671: SourceChangeWarning: source code of class 'models.common.Concat' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:671: SourceChangeWarning: source code of class 'models.yolo.Detect' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOv5 logging with 'pip install wandb' (recommended)\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    156928  models.common.C3                        [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "Model Summary: 283 layers, 7063542 parameters, 7063542 gradients, 16.4 GFLOPs\n",
      "\n",
      "Transferred 156/362 items from last_yolov5s_results.pt\n",
      "Scaled weight_decay = 0.00046875\n",
      "Optimizer groups: 62 .bias, 62 conv.weight, 59 other\n",
      "last_yolov5s_results.pt has been trained for 99 epochs. Fine-tuning for 10 additional epochs.\n",
      "WARNING: --img-size 400 must be multiple of max stride 32, updating to 416\n",
      "DP not recommended, instead use torch.distributed.run for best DDP Multi-GPU results.\n",
      "See Multi-GPU Tutorial at https://github.com/ultralytics/yolov5/issues/475 to get started.\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'working/data/labels/train.cache' images and labels... 24 found,\u001b[0m\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label working/data/images/train/test_1211.jpg: negative labels\n",
      "\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.0GB):   4%|‚ñå            | 1/23 [00:00<00:08,  2.63it/s]\u001b[0m\u001b[A\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.0GB):  22%|‚ñà‚ñà‚ñä          | 5/23 [00:00<00:01, 11.05it/s]\u001b[0m\u001b[A\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.0GB):  39%|‚ñà‚ñà‚ñà‚ñà‚ñà        | 9/23 [00:00<00:00, 16.55it/s]\u001b[0m\u001b[A\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.0GB):  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä     | 13/23 [00:00<00:00, 20.09it/s]\u001b[0m\u001b[A\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.0GB):  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/23 [00:00<00:00, 23.18it/s]\u001b[0m\u001b[A\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.0GB): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:01<00:00, 21.25it/s]\u001b[0m\u001b[A\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'working/data/labels/train.cache' images and labels... 24 found,\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'working/data/labels/train.cache' images and labels... 24 found,\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'working/data/labels/valid.cache' images and labels... 6 found, 0 \u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'working/data/labels/valid.cache' images and labels... 6 found, 0 \u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:00<00:00, 12.07it/s]\u001b[0m\u001b[A\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 658, in <module>\n",
      "    main(opt)\n",
      "  File \"train.py\", line 556, in main\n",
      "    train(opt.hyp, opt, device)\n",
      "  File \"train.py\", line 238, in train\n",
      "    prefix=colorstr('val: '))[0]\n",
      "  File \"/home/jupyter/peet/Yolo/yolov5/utils/datasets.py\", line 116, in create_dataloader\n",
      "    collate_fn=LoadImagesAndLabels.collate_fn4 if quad else LoadImagesAndLabels.collate_fn)\n",
      "  File \"/home/jupyter/peet/Yolo/yolov5/utils/datasets.py\", line 129, in __init__\n",
      "    self.iterator = super().__iter__()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 359, in __iter__\n",
      "    return self._get_iterator()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 305, in _get_iterator\n",
      "    return _MultiProcessingDataLoaderIter(self)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 918, in __init__\n",
      "    w.start()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 112, in start\n",
      "    self._popen = self._Popen(self)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/context.py\", line 223, in _Popen\n",
      "    return _default_context.get_context().Process._Popen(process_obj)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/context.py\", line 277, in _Popen\n",
      "    return Popen(process_obj)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/popen_fork.py\", line 20, in __init__\n",
      "    self._launch(process_obj)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/popen_fork.py\", line 70, in _launch\n",
      "    self.pid = os.fork()\n",
      "OSError: [Errno 12] Cannot allocate memory\n"
     ]
    }
   ],
   "source": [
    "!python train.py --img 400 --batch 10 --epochs 10 --data './working/new_data_yaml' --cfg './models/yolov5s.yaml' --weights 'last_yolov5s_results.pt' --name joos --nosave --cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b8e15eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['./runs/train/joos16/weights/best.pt'], source=./test_1318.jpg, imgsz=416, conf_thres=0.2, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=True, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False\n",
      "YOLOv5 üöÄ v5.0-301-g0cc7c58 torch 1.9.0+cu102 CUDA:0 (Tesla T4, 15109.75MB)\n",
      "\n",
      "Fusing layers... \n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "Model Summary: 224 layers, 7053910 parameters, 0 gradients, 16.3 GFLOPs\n",
      "image 1/1 /home/jupyter/peet/Yolo/yolov5/test_1318.jpg: 416x320 Done. (0.009s)\n",
      "Results saved to runs/detect/exp3\n",
      "0 labels saved to runs/detect/exp3/labels\n",
      "Done. (0.284s)\n"
     ]
    }
   ],
   "source": [
    "!python detect.py --source './test_1318.jpg' --weights './runs/train/joos16/weights/best.pt' --img 416 --conf 0.20 --save-txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fd41c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca8714f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test_1318.txt',\n",
       " 'test_1340.txt',\n",
       " 'test_1400.txt',\n",
       " 'test_1337.txt',\n",
       " 'test_1379.txt',\n",
       " '.ipynb_checkpoints',\n",
       " 'test_1371.txt']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(os.listdir('./working/data/labels/valid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7911f5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test_1371.jpg',\n",
       " 'test_1340.jpg',\n",
       " 'test_1337.jpg',\n",
       " 'test_1318.jpg',\n",
       " 'test_1379.jpg',\n",
       " '.ipynb_checkpoints',\n",
       " 'test_1400.jpg']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(os.listdir('./working/data/images/valid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e87993c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom model config written!\n"
     ]
    }
   ],
   "source": [
    "##write custom model .yaml\n",
    "#you can configure this based on other YOLOv5 models in the models directory\n",
    "with open('./models/custom_yolov5s.yaml', 'w') as f:\n",
    "    # parameters\n",
    "\n",
    "    f.write('nc: ' + str(1) + '\\n')\n",
    "    #f.write('nc: ' + str(len(class_labels)) + '\\n')\n",
    "    f.write('depth_multiple: 0.33'  + '\\n') # model depth multiple\n",
    "    f.write('width_multiple: 0.50'  + '\\n')  # layer channel multiple\n",
    "    f.write('\\n')\n",
    "    f.write('anchors:' + '\\n')\n",
    "    f.write('  - [10,13, 16,30, 33,23] ' + '\\n')\n",
    "    f.write('  - [30,61, 62,45, 59,119]' + '\\n')\n",
    "    f.write('  - [116,90, 156,198, 373,326] ' + '\\n')\n",
    "    f.write('\\n')\n",
    "\n",
    "    f.write('backbone:' + '\\n')\n",
    "    f.write('  [[-1, 1, Focus, [64, 3]],' + '\\n')\n",
    "    f.write('   [-1, 1, Conv, [128, 3, 2]],' + '\\n')\n",
    "    f.write('   [-1, 3, Bottleneck, [128]],' + '\\n')\n",
    "    f.write('   [-1, 1, Conv, [256, 3, 2]],' + '\\n')\n",
    "    f.write('   [-1, 9, BottleneckCSP, [256]],' + '\\n')\n",
    "    f.write('   [-1, 1, Conv, [512, 3, 2]], ' + '\\n')\n",
    "    f.write('   [-1, 9, BottleneckCSP, [512]],' + '\\n')\n",
    "    f.write('   [-1, 1, Conv, [1024, 3, 2]],' + '\\n')\n",
    "    f.write('   [-1, 1, SPP, [1024, [5, 9, 13]]],' + '\\n')\n",
    "    f.write('   [-1, 6, BottleneckCSP, [1024]],' + '\\n')\n",
    "    f.write('  ]' + '\\n')\n",
    "    f.write('\\n')\n",
    "\n",
    "    f.write('head:'  + '\\n')\n",
    "    f.write('  [[-1, 3, BottleneckCSP, [1024, False]],'  + '\\n')\n",
    "    f.write('   [-1, 1, nn.Conv2d, [na * (nc + 5), 1, 1, 0]],' + '\\n')\n",
    "    f.write('   [-2, 1, nn.Upsample, [None, 2, \"nearest\"]],' + '\\n')\n",
    "\n",
    "    f.write('   [[-1, 6], 1, Concat, [1]],' + '\\n')\n",
    "    f.write('   [-1, 1, Conv, [512, 1, 1]],' + '\\n')\n",
    "    f.write('   [-1, 3, BottleneckCSP, [512, False]],' + '\\n')\n",
    "    f.write('   [-1, 1, nn.Conv2d, [na * (nc + 5), 1, 1, 0]],' + '\\n')\n",
    "\n",
    "    f.write('   [-2, 1, nn.Upsample, [None, 2, \"nearest\"]],' + '\\n')\n",
    "    f.write('   [[-1, 4], 1, Concat, [1]],' + '\\n')\n",
    "    f.write('   [-1, 1, Conv, [256, 1, 1]],' + '\\n')\n",
    "    f.write('   [-1, 3, BottleneckCSP, [256, False]],' + '\\n')\n",
    "    f.write('   [-1, 1, nn.Conv2d, [na * (nc + 5), 1, 1, 0]],' + '\\n')\n",
    "    f.write('\\n' )\n",
    "    f.write('   [[], 1, Detect, [nc, anchors]],' + '\\n')\n",
    "    f.write('  ]' + '\\n')\n",
    "\n",
    "print('custom model config written!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e972e852",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.m74",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m74"
  },
  "kernelspec": {
   "display_name": "peet_kernel",
   "language": "python",
   "name": "peet_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
